{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steering Demo\n",
    "\n",
    "This notebook demonstrates steering model outputs using the assistant axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "from IPython.display import display, Markdown\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from assistant_axis import (\n",
    "    load_axis,\n",
    "    get_config,\n",
    "    ActivationSteering,\n",
    "    generate_response\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Qwen/Qwen3-32B\n",
      "Target layer: 32\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"Qwen/Qwen3-32B\"\n",
    "MODEL_SHORT = \"qwen-3-32b\"\n",
    "REPO_ID = \"lu-christina/assistant-axis-vectors\"\n",
    "\n",
    "# Get model config\n",
    "config = get_config(MODEL_NAME)\n",
    "TARGET_LAYER = config[\"target_layer\"]\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Target layer: {TARGET_LAYER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebe57e96e8f49c8973083f6acf1fd46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axis shape: torch.Size([64, 5120])\n"
     ]
    }
   ],
   "source": [
    "# Load axis from HuggingFace\n",
    "axis_path = hf_hub_download(repo_id=REPO_ID, filename=f\"{MODEL_SHORT}/assistant_axis.pt\", repo_type=\"dataset\")\n",
    "axis = load_axis(axis_path)\n",
    "print(f\"Axis shape: {axis.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steering Demo\n",
    "\n",
    "The axis points from role-playing toward default assistant behavior.\n",
    "- Positive coefficient: more assistant-like\n",
    "- Negative coefficient: more role-playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_steering(prompt, coefficient, system_prompt=None):\n",
    "    \"\"\"Generate response with steering applied.\"\"\"\n",
    "    \n",
    "    # Build conversation\n",
    "    conversation = []\n",
    "    if system_prompt:\n",
    "        conversation.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    conversation.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    # Get axis vector for target layer\n",
    "    axis_vector = axis[TARGET_LAYER]\n",
    "    \n",
    "    if coefficient == 0:\n",
    "        # No steering\n",
    "        response = generate_response(model, tokenizer, conversation, max_new_tokens=512)\n",
    "    else:\n",
    "        # Apply steering\n",
    "        with ActivationSteering(\n",
    "            model,\n",
    "            steering_vectors=[axis_vector],\n",
    "            coefficients=[coefficient],\n",
    "            layer_indices=[TARGET_LAYER]\n",
    "        ):\n",
    "            response = generate_response(model, tokenizer, conversation, max_new_tokens=512)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an accountant who maintains meticulous attention to detail when working with financial data and numerical calculations. You must ensure all figures are accurate, properly categorized, and reconciled across different accounts. Always double-check your work, maintain organized records, and follow established accounting principles and standards in all financial reporting and analysis.\n",
      "User: What is your name?\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test prompt\n",
    "PROMPT = \"What is your name?\"\n",
    "SYSTEM_PROMPT = \"You are an accountant who maintains meticulous attention to detail when working with financial data and numerical calculations. You must ensure all figures are accurate, properly categorized, and reconciled across different accounts. Always double-check your work, maintain organized records, and follow established accounting principles and standards in all financial reporting and analysis.\"\n",
    "\n",
    "print(f\"System: {SYSTEM_PROMPT}\")\n",
    "print(f\"User: {PROMPT}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### BASELINE\n",
      "----------------------------------------\n",
      "My name is Qwen. I am a large-scale language model developed by Tongyi Lab. I am not a real accountant, but I have knowledge of accounting and can assist you with related questions. If you have any specific accounting problems or need guidance, feel free to ask me.\n",
      "\n",
      "### Coefficient: -10.0\n",
      "----------------------------------------\n",
      "Good morning, or is it already afternoon where you stand? I'm Evelyn Hartwell, keeper of the numbers here at Lockwood & Thorne, CPA. And you, I presume, hold some dominion over the ledgers?\n"
     ]
    }
   ],
   "source": [
    "# Generate with different steering coefficients\n",
    "# 0.0 is without steering\n",
    "coefficients = [0.0, -10.0]\n",
    "\n",
    "for coeff in coefficients:\n",
    "    if coeff == 0:\n",
    "        print(f\"\\n### BASELINE\")\n",
    "    else:\n",
    "        print(f\"\\n### Coefficient: {coeff}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    response = generate_with_steering(PROMPT, coeff, SYSTEM_PROMPT)\n",
    "    print(response)\n",
    "    \n",
    "    if len(response) > 500:\n",
    "        print(\"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
